% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={E資格 レベルアップ問題集},
  pdfauthor={IRIE NORIFUMI},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{E資格 レベルアップ問題集}
\author{IRIE NORIFUMI}
\date{}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\bookmarksetup{startatroot}

\chapter{Introduction}\label{introduction}

This is a book created from markdown and executable code.

See @knuth84 for additional discussion of literate programming.

\part{2.機械学習(Machine Learning)}

\chapter{1. 機械学習の基礎 (Machine Learning
Basics)}\label{ux6a5fux68b0ux5b66ux7fd2ux306eux57faux790e-machine-learning-basics}

\part{3.深層学習基礎(Basic Deep-learning)}

\chapter{2. 順伝播型ネットワーク (Feedforward Neural
Network)}\label{ux9806ux4f1dux64adux578bux30cdux30c3ux30c8ux30efux30fcux30af-feedforward-neural-network}

\chapter{3. 畳み込みニューラルネットワーク (Convolutional
Neural)}\label{ux7573ux307fux8fbcux307fux30cbux30e5ux30fcux30e9ux30ebux30cdux30c3ux30c8ux30efux30fcux30af-convolutional-neural}

ある1枚の画像（1チャンネル）に対して、次の条件で im2col 変換を行う。\\
入力画像サイズ：5×5\\
フィルターサイズ：3×3\\
ストライド：1\\
パディング：0\\
このとき、im2colによって生成される行列の形状（im\_col.shape）として最も適切なものはどれか。
ただし、フィルターは1枚であり、チャンネル数は1とする。

A. (3, 3)\\
B. (9, 9)\\
C. (9, 25)\\
D. (3, 9)

\part{第4章.深層学習応用(Advanced Deep-learning)}

\chapter{2. 物体検出(Object
Detection)}\label{ux7269ux4f53ux691cux51faobject-detection}

\subsection{問1}\label{ux554f1}

以下のうち、FCOSについて誤っているものはどれか。\\
A. FCOSはアンカーボックスのサイズ・アスペクト比・数を事前に設定する。\\
B. FCOSはFeature Pyramid
Network(FPN)により生成される複数のサイズの特徴マップを用いて、大小様々な物体を検出できる。\\
C. FCOS
はバウンディングボックスの座標ではなく、各ピクセル座標においてフレームまでの距離を回帰する。\\
D. FCOS
では対象物体の中心から離れた位置に低品質の予測バウンディングボックスが生成されるため、対策としてCenter-nessブランチが導入された。

\subsection{問2}\label{ux554f2}

R-CNNの英語名(A)を答えよ。
また、この名称の由来となったROIに関して、ROIを見つけ出すアルゴリズムの総称(B)と、R-CNNにおけるアルゴリズムの手法(C)を答えよ。

\chapter{3. Semantic Segmentation (Semantic
Segmentation)}\label{semantic-segmentation-semantic-segmentation}

\subsection{問1}\label{ux554f1-1}

FCN（Fully Convolutional
Network）は、画像のセマンティックセグメンテーションのために設計されたネットワークであり、全結合層の代わりに（あ）を用いて、入力画像と同じ空間解像度の出力を得ることが可能である。また、分類タスクで用いられる典型的なCNN（例：VGG,
ResNet）をベースとして、出力特徴マップを元の画像サイズに戻すために、（い）と呼ばれる処理を用いてアップサンプリングを行う。このとき、例えばFCN-32s、FCN-16s、FCN-8sのようにダウンサンプリング段階ごとの特徴マップを結合することで、より高解像度な出力を得ることができる。これにより、粗い予測に対して（う）の情報を加えることが可能となる。
FCNの出力に対して、セマンティックセグメンテーションでは次のようなピクセル単位の損失関数が用いられる。
\[
𝐿=−∑_{𝑥∈Ω}∑_{c∈C}y_c(x)logP_c(x)
\]
ここで、\(y_c(x)\)は位置\(x\)における正解ラベルのone-hot表現、\(P_c(x)\)はクラス\(c\)に属する確率であり、（え）関数により出力される。

A. (あ) 全結合層 (い) 転置畳み込み（Transposed Conv） (う)
スキップコネクション (え) シグモイド\\
B. (あ) 畳み込み層 (い) 補間（Interpolation） (う) バッチ正規化 (え)
ReLU\\
C. (あ) 畳み込み層 (い) 転置畳み込み（Transposed Conv） (う)
スキップコネクション (え) ソフトマックス\\
D. (あ) 全結合層 (い) プーリング (う) 逆畳み込み (え) シグモイド

\chapter{4. 自然言語処理 (Natural Language
Processing)}\label{ux81eaux7136ux8a00ux8a9eux51e6ux7406-natural-language-processing}

\subsection{問1}\label{ux554f1-2}

以下のSeq2Seqの説明について、空欄（ア）～（ウ）に埋まる言葉として正しいものを選べ。
エンコーダへの入力系列とデコーダからの出力系列は（ア）にすることができる。
最小化する対象は、（イ） で表すことができる。
文脈の長さを固定したとき、入力系列が（ウ）とエンコードの性能を担保することができない。

A.（ア）異なる長さ（イ）+logP（yの系列\textbar✕の系列）（ウ）短すぎる\\
B.（ア） 異なる長さ（イ）-logP（yの系列\textbar xの系列）（ウ）
長すぎる\\
C.（ア）同じ重み（イ）+logP（yの系列\textbar✕の系列）（ウ） 長すぎる\\
D.（ア） 同じ重み（イ）-logP（yの系列xの系列）（ウ） 短すぎる

\subsection{問2}\label{ux554f2-1}

Word2VecのSkip-gramモデルは、ある単語からその周囲の単語を予測することで単語ベクトル（埋め込み）を学習する手法である。しかし語彙数が多い自然言語コーパスでは、softmax関数を使って全語彙から予測対象の単語を選ぶことは非常に高コストである。この問題を解決するために導入される技法のひとつが「ネガティブサンプリング」である。ネガティブサンプリングに関する以下の記述のうち、最も適切なものはどれか。

A.
ネガティブサンプリングでは、語彙全体にsoftmaxを適用し、確率分布を正規化して損失関数を計算することで効率化を実現している。\\
B.
ネガティブサンプリングでは、実際に出現したコンテキスト語のみを使用し、負例を使わずに分類を行う。\\
C.
ネガティブサンプリングでは、中心語と正しいコンテキスト語のペアを正例として扱い、それ以外のランダムに選んだ語を負例とすることで、計算負荷を大幅に削減している。\\
D.
ネガティブサンプリングでは、skip-gramではなくCBOWモデルにのみ適用可能であるため、効率性の面で制限がある。

\chapter{5. Recurrent Neural Network (Recurrent Neural
Network)}\label{recurrent-neural-network-recurrent-neural-network}

\subsection{問1}\label{ux554f1-3}

次のプログラムはLSTMの各時刻tでの中間層計算の処理を記述したものである。
LSTMは従来のRNNに比べてゲート制御用の重みの重みやバイアスの種類が多く、似たような計算をなんども行う必要がある。計算を効率よく行うために中間層伝播、ゲート3種類を計算するために必要な、「入力」と「前時刻の中間層出力」の重み付き線形和はまとめて計算する。

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_input }\OperatorTok{=} \DecValTok{100}  
\NormalTok{n\_hidden }\OperatorTok{=} \DecValTok{256}

\NormalTok{w }\OperatorTok{=}\NormalTok{ （あ）  }
\NormalTok{b }\OperatorTok{=}\NormalTok{ np.zeros(n\_hidden }\OperatorTok{*} \DecValTok{4}\NormalTok{)}

\CommentTok{\# x は（バッチサイズ、入力長）の行列  }
\CommentTok{\# h, c は（バッチサイズ、中間層ユニット数）の行列  }
\KeywordTok{def}\NormalTok{ lstm(x, h, c):  }
    \CommentTok{\# ゲートおよび入力の Wx + Uh + b の項をまとめて計算  }
\NormalTok{    inputs }\OperatorTok{=}\NormalTok{ np.concatenate((x, h), axis}\OperatorTok{=}\DecValTok{1}\NormalTok{)  }
\NormalTok{    inputs }\OperatorTok{=}\NormalTok{ np.matmul(inputs, w) }\OperatorTok{+}\NormalTok{ b  }
\NormalTok{    z, i, f, o }\OperatorTok{=}\NormalTok{ np.hsplit(inputs, }\DecValTok{4}\NormalTok{)  }
\NormalTok{    ...}
\end{Highlighting}
\end{Shaded}

(あ)に当てはまる式として正しいものを、以下の選択肢から選べ。

A. np.random.randn(n\_input * n\_hidden, n\_hidden * 3)\\
B. np.random.randn(n\_input * n\_hidden, n\_hidden * 4)\\
C. np.random.randn(n\_input + n\_hidden, n\_hidden * 3)\\
D np.random.randn(n\_input + n\_hidden, n\_hidden * 4)

\subsection{問2}\label{ux554f2-2}

LSTMとGRU(Gated Recurrent
Unit)について、それぞれに含まれるゲートの名称を答えよ。

\chapter{6. 生成モデル (Generative
Model)}\label{ux751fux6210ux30e2ux30c7ux30eb-generative-model}

\subsection{問1}\label{ux554f1-4}

次の選択肢の中から誤ったものを1つ選べ。

A.
変分自己符号化器（VAE）は潜在空間の分布を正規分布などの簡単な分布に制約することで、生成過程を安定化させている。Reparameterization
Trick により、勾配のバックプロパゲーションが可能となっている。\\
B. Denoising Autoencoder
は、入力データにノイズを加えてから復元することで、より堅牢な特徴表現の学習を促進するオートエンコーダの一種である。\\
C.
フローベース生成モデルは、潜在空間からサンプルを生成するときに、逆変換を用いて生成過程を効率的に計算できるが、逆変換のヤコビアン行列の行列式を計算するコストが非常に低いことも特徴の一つである。\\
D.
敵対的生成ネットワーク（GAN）は、生成器と識別器が交互に学習し、生成器は識別器を欺くためのリアルなサンプル生成を目指すが、VAEと比較して生成されるサンプルの多様性が劣る傾向がある。

\chapter{7. 深層強化学習 (Reinforcement
Learning)}\label{ux6df1ux5c64ux5f37ux5316ux5b66ux7fd2-reinforcement-learning}

\subsection{問1}\label{ux554f1-5}

DQNにおいて、Q学習の一部である「TD誤差」は以下のように定義される。
次の空欄（あ）に入る適切な語句を選べ。 \[
TD誤差 = [あ] − Q(s, a)
\] A. Q(s', a') の平均値\\
B. 実際に得られた報酬\\
C. \({γ * Q(s, a)}\)\\
D. \({R(s, a) + γ * maxQ(s', a')}\)

\subsection{問2}\label{ux554f2-3}

強化学習の基本的なアルゴリズムのうちの一つとして、ベルマン方程式に従って行動価値関数\(𝑄(𝑠, 𝑎)\)をモデル化する価値反復に基づく方法が挙げられる。しかしこの方法では行動𝑎が連続な値を取る場合ような場合を自然に扱えないといった欠点がある。そうした問題に対応する方法として、方策自体をパラメータ𝜃を用いて\(𝜋_𝜃(𝑎|𝑠)\)のようにモデル化した方策勾配に基づくアルゴリズムが挙げられる。方策勾配に基づくアルゴリズムにおいては方策勾配の定理により目的関数\(𝐽_𝜃 = 𝑉(𝑠_0)\)の𝜃に関する勾配\(∇_𝜃𝐽(𝜃)\)を以下のように計算できる。
\[
∇_𝜃𝐽(𝜃) = 𝔼_{𝜋_𝜃}[(あ)]
\]

こうして計算された勾配を用いて勾配法により、方策𝜋\_𝜃(𝑎\textbar 𝑠)
をアップデートするのが方策勾配に 基づくアルゴリズムである。
(あ)に当てはまる式として正しいものを、以下の選択肢から選べ。

A. \(∇_𝜃log𝜋_𝜃(𝑎|𝑠)𝑄^𝜋(𝑠,𝑎)\)\\
B. \(∇_𝜃𝜋_𝜃(𝑎|𝑠)𝑄^𝜋(𝑠,𝑎)\)\\
C. \(\frac{∇_𝜃𝜋_𝜃(𝑎|𝑠)}{𝑄^𝜋(𝑠,𝑎)}\)\\
D. \(\frac{𝑄^𝜋(𝑠,𝑎)}{∇_𝜃𝜋_𝜃(𝑎|𝑠)}\)

\chapter{8. 様々な学習方法 (Various Learning
Methods)}\label{ux69d8ux3005ux306aux5b66ux7fd2ux65b9ux6cd5-various-learning-methods}

\subsection{問1}\label{ux554f1-6}

深層学習技術を用いた距離学習手法としては他にも、Triplet
Networkなどがある。Triplet NetworkもSiamese
Networkと同様に、類似サンプル間の距離を近く・非類似サンプル間の距離を遠くするように表現学習が行われる。Siamese
Network は2つのサンプルを入力としたが、Triplet
Networkでは3つのサンプルをひと組の入力とする。3つのサンプルは、基準となるアンカーサンプルと、アンカーサンプルとの類似サンプル及び非類似サンプルにより構成される。アンカーサンプルと類似サンプル間の距離を\({d_p}\)、アンカーサンプルと非類似サンプル間の距離を\({d_n}\)、類似サンプルと非類似サンプル間のマージンをmとしたとき、最小化したい目的関数
triplet loss Lは \[
L ＝（い）
\]

と表される。空欄（い）に当てはまる式として正しいものを、以下の選択肢から選べ。

A. \({max(d_p - d_n + m, 0)}\)\\
B. \({max(d_p - d_n, m)}\)\\
C. \({max(-d_p + d_n, m)}\)\\
D. \({max(d_p - d_n - m, 0)}\)

\subsection{問2}\label{ux554f2-4}

以下の選択肢から、距離学習に関する説明として間違っているものを選べ。

A. Triplet Network
では、学習時の入力ペアの選び方に、学習されたモデルの性能が依存しない。\\
B. Siamese Network
では、類似しない2つのサンプル間の距離が全てマージンの値に収束するように学習が行われる。\\
C. Siamese Network
では2つのサンプルが同じ・違うものというコンテキストを固定する必要があるが、Triplet
Network
では「アンカーサンプルが残り2つのサンプルのどちらにより類似しているか」という基準で学習できるため、学習時のコンテキストに関する制約が緩和されている。\\
D. Triplet Network
では、学習データセットサイズが増えるとペアの数が爆発的に増えるという課題がある。

\chapter{9. 深層学習の説明性 (Explainability of
Deep-learning)}\label{ux6df1ux5c64ux5b66ux7fd2ux306eux8aacux660eux6027-explainability-of-deep-learning}

\subsection{問1}\label{ux554f1-7}

次の文章は Grad-CAM（Gradient-weighted Class Activation
Mapping）の説明である。間違っているものはどれか、1つ選びなさい。

A.
AlexNetのように最後が畳み込み層ではなく、全結合層であるCNNには適用出来ない\\
B.
Grad-CAMを適用するために、アーキテクチャの変更や再トレーニングを行う必要がない\\
C. Guided Grad-CAMは、Grad-CAMとGuided
Backpropagationを組み合わせたものである\\
D.
CNNの最終的な畳み込み層の出力値に対する勾配を利用してカラーマップ表示するための値を求める

\subsection{問2}\label{ux554f2-5}

Shapley値は協力ゲーム理論に基づき、特徴量の寄与度を計算する。
次のうち、Shapley値の計算に必ず含まれる考え方として正しいものを選べ。

A. 各特徴量を1つずつ除去したモデルの予測差を合計して寄与度とする。\\
B.
全ての特徴量の順列（Permutation）について、各特徴量が追加されたときの限界貢献度の平均を取る。\\
C. 特徴量間の相関を完全に無視して寄与度を算出する。\\
D. 各特徴量の寄与度は必ず正の値になる

\part{第5章.開発・運用環境(Infrastructure)}

\chapter{4. アクセラレーター
(Accelerator)}\label{ux30a2ux30afux30bbux30e9ux30ecux30fcux30bfux30fc-accelerator}

\subsection{問1}\label{ux554f1-8}

近年、ディープラーニングによるAIが大きな成功を収めつつあることを背景として、ディープラーニングの演算に適した新しいプロセッサが開発されている。代表的なプロセッサに
Googleが開発したTPU （Tensor Processing
Unit）がある。次の選択肢はTPUあるいはGPUを説明した記述である。GPUに当てはまる記述を選べ。

A.メモリにデータとプログラムを内蔵しメモリから命令を逐次取り出し実行するノイマン型プロセッサの一種である。\\
B.数千の積和演算器が配置され、それらが互いに直接接続されている。このアーキテクチャはシストリックアレイと呼ばれている。\\
C.演算の結果をメモリではなく次の乗算器に渡すことでメモリアクセスの必要を無くし、スループットを向上させている。\\
D.演算器の計算精度を8bitや16bitのみにすることで、スループットの向上や低消費電力化を図っている。

\bookmarksetup{startatroot}

\chapter{解答一覧}\label{ux89e3ux7b54ux4e00ux89a7}

\bookmarksetup{startatroot}

\chapter{第3章.深層学習基礎(Basic
Deep-learning)}\label{ux7b2c3ux7ae0.ux6df1ux5c64ux5b66ux7fd2ux57faux790ebasic-deep-learning}

\section{3. 畳み込みニューラルネットワーク (Convolutional
Neural)}\label{ux7573ux307fux8fbcux307fux30cbux30e5ux30fcux30e9ux30ebux30cdux30c3ux30c8ux30efux30fcux30af-convolutional-neural-1}

問1. B

\bookmarksetup{startatroot}

\chapter{第4章.深層学習応用(Advanced
Deep-learning)}\label{ux7b2c4ux7ae0.ux6df1ux5c64ux5b66ux7fd2ux5fdcux7528advanced-deep-learning-1}

\section{2. 物体検出(Object
Detection)}\label{ux7269ux4f53ux691cux51faobject-detection-1}

問1. A\\
問2. A: Region-based Convolutional Neural Network\\
B: Region Proposal(領域探索)\\
C: Selective Search

\section{3. Semantic Segmentation (Semantic
Segmentation)}\label{semantic-segmentation-semantic-segmentation-1}

問1. C

\section{4. 自然言語処理 (Natural Language
Processing)}\label{ux81eaux7136ux8a00ux8a9eux51e6ux7406-natural-language-processing-1}

問1. B\\
問2. C

\section{5. Recurrent Neural Network (Recurrent Neural
Network)}\label{recurrent-neural-network-recurrent-neural-network-1}

問1. D\\
問2. LSTM: 忘却ゲート(Forget Gate)、入力ゲート(Input
Gate)、出力ゲート(Output Gate)、記憶セル(Memory Cell)\\
GRU: リセットゲート(Reset Gate)、更新ゲート(Update Gate)

\section{6. 生成モデル (Generative
Model)}\label{ux751fux6210ux30e2ux30c7ux30eb-generative-model-1}

問1. C

\section{7. 深層強化学習 (Reinforcement
Learning)}\label{ux6df1ux5c64ux5f37ux5316ux5b66ux7fd2-reinforcement-learning-1}

問1. D\\
問2. A

\section{8. 様々な学習方法 (Various Learning
Methods)}\label{ux69d8ux3005ux306aux5b66ux7fd2ux65b9ux6cd5-various-learning-methods-1}

問1. A\\
問2. A

\section{9. 深層学習の説明性 (Explainability of
Deep-learning)}\label{ux6df1ux5c64ux5b66ux7fd2ux306eux8aacux660eux6027-explainability-of-deep-learning-1}

問1. A\\
問2. B

\bookmarksetup{startatroot}

\chapter{第5章.開発・運用環境(Infrastructure)}\label{ux7b2c5ux7ae0.ux958bux767aux904bux7528ux74b0ux5883infrastructure-1}

\section{4. アクセラレーター
(Accelerator)}\label{ux30a2ux30afux30bbux30e9ux30ecux30fcux30bfux30fc-accelerator-1}

問1. A

\bookmarksetup{startatroot}

\chapter{参考文献}\label{ux53c2ux8003ux6587ux732e}

問題作成及び内容の理解を深めるにあたり、以下のリソースを参考にしました。

\begin{itemize}
\tightlist
\item
  \href{https://www.youtube.com/watch?v=50XvMaWhiTY}{【深層学習】Transformer
  - Multi-Head
  Attentionを理解してやろうじゃないの【ディープラーニングの世界vol.28】}
\item
  \href{https://note.com/kikaben/n/n1b8b8fa1a0e6}{情報理論：KLダイバージェンス}
\item
  \href{https://engineernoi.hatenablog.com/entry/2024/05/12/233601}{E資格のためのフローベース生成モデル}
\item
  \href{https://ai4mdx.com/index.html}{E資格合格へのロードマップ}
\end{itemize}




\end{document}
